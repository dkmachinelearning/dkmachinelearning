{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKgxlclPn50aZhTgaoCDlm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkmachinelearning/dkmachinelearning/blob/main/MLPRegressor_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FhaN24naD-oE"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "#\n",
        "# Load California housing data set\n",
        "#\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n"
      ],
      "metadata": {
        "id": "rgbi5vnhEN0O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "2224a458-2d24-4bf1-e2fb-0787b03cbf33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a04f7a6552fb>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load California housing data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhousing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_california_housing.py\u001b[0m in \u001b[0;36mfetch_california_housing\u001b[0;34m(data_home, download_if_missing, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0marchive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARCHIVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_home\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_base.py\u001b[0m in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m     \u001b[0mchecksum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mchecksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print(pd.DataFrame(X).describe())\n",
        "print('\\n')\n",
        "print(pd.DataFrame(X).info())"
      ],
      "metadata": {
        "id": "j7lVPMS0GCv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking NaNs - it's not nessesary\n",
        "nan_cols = []\n",
        "for col in pd.DataFrame(X).columns:\n",
        "    if pd.DataFrame(X)[col].isnull().any():\n",
        "        print(col, pd.DataFrame(X)[col].isnull().sum())\n",
        "        nan_cols.append(col)\n",
        "    else:\n",
        "      print('There\\'s no NaNs in data')"
      ],
      "metadata": {
        "id": "VyQx6ozCHYEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NN without scaling\")\n",
        "\n",
        "# Create training/ test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Instantiate MLPRegressor\n",
        "nn = MLPRegressor(random_state=1)\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction\n",
        "pred = nn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and error metrics\n",
        "test_set_rsquared = nn.score(X_test, y_test)\n",
        "test_set_rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "\n",
        "# Print R_squared and RMSE value\n",
        "print(f'R_squared value: , {test_set_rsquared:.2f} %')\n",
        "print(f'RMSE: , {test_set_rmse:.2f} %')"
      ],
      "metadata": {
        "id": "w9b63zSAENt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NN with StandardScaler\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_ss = scaler.fit_transform(X)\n",
        "\n",
        "# Create training/ test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Instantiate MLPRegressor\n",
        "nn = MLPRegressor(random_state=1)\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction\n",
        "pred = nn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and error metrics\n",
        "test_set_rsquared = nn.score(X_test, y_test)\n",
        "test_set_rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "\n",
        "# Print R_squared and RMSE value\n",
        "print(f'R_squared value: , {test_set_rsquared:.2f} %')\n",
        "print(f'RMSE: , {test_set_rmse:.2f} %')"
      ],
      "metadata": {
        "id": "EI1R1v-0ENnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NN with MinMaxScaler\")\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_mm = scaler.fit_transform(X)\n",
        "\n",
        "# Create training/ test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_mm, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Instantiate MLPRegressor, more iterations needed\n",
        "nn = MLPRegressor(random_state=1, max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction\n",
        "pred = nn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and error metrics\n",
        "test_set_rsquared = nn.score(X_test, y_test)\n",
        "test_set_rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "\n",
        "# Print R_squared and RMSE value\n",
        "print(f'R_squared value: , {test_set_rsquared:.2f} %')\n",
        "print(f'RMSE: , {test_set_rmse:.2f} %')"
      ],
      "metadata": {
        "id": "v5EmLdGGENhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NN with MaxAbsScaler\")\n",
        "\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_ma = scaler.fit_transform(X)\n",
        "\n",
        "# Create training/ test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_ma, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Instantiate MLPRegressor, more iterations needed\n",
        "nn = MLPRegressor(random_state=1, max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction\n",
        "pred = nn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and error metrics\n",
        "test_set_rsquared = nn.score(X_test, y_test)\n",
        "test_set_rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "\n",
        "# Print R_squared and RMSE value\n",
        "print(f'R_squared value: , {test_set_rsquared:.2f} %')\n",
        "print(f'RMSE: , {test_set_rmse:.2f} %')"
      ],
      "metadata": {
        "id": "CzyYpY8gENah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NN with RobustScaler\")\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_rb = scaler.fit_transform(X)\n",
        "\n",
        "# Create training/ test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rb, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Instantiate MLPRegressor, more iterations needed\n",
        "nn = MLPRegressor(random_state=1, max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction\n",
        "pred = nn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and error metrics\n",
        "test_set_rsquared = nn.score(X_test, y_test)\n",
        "test_set_rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "\n",
        "# Print R_squared and RMSE value\n",
        "print(f'R_squared value: , {test_set_rsquared:.2f} %')\n",
        "print(f'RMSE: , {test_set_rmse:.2f} %')"
      ],
      "metadata": {
        "id": "3PPNGHmMENT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"StandardSlaer was the best. Now it's time for hyperparameters optimization\")\n",
        "\n",
        "#Last T&T split\n",
        "# Create training/ test data split with StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Instantiate MLPRegressor, more max_iterations just in case\n",
        "nn = MLPRegressor(random_state=1, max_iter=2000)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Found great trick for making combination of neurons in layers :)\n",
        "from itertools import product\n",
        "first_layer_neurons = np.arange(5, 100, 5)\n",
        "second_layer_neurons = np.arange(5, 100, 5)\n",
        "hidden_layer_sizes = list(product(first_layer_neurons, second_layer_neurons))\n",
        "\n",
        "#preparing dict with hyperparams for optimization\n",
        "param_list = {\n",
        "    \"hidden_layer_sizes\": hidden_layer_sizes,\n",
        "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
        "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
        "    \"alpha\": np.arange(0.000005, 0.1, 0.005)}\n",
        "search = GridSearchCV(estimator=nn, param_grid=param_list, n_jobs = -1, cv = 5, verbose = 3)\n",
        "\n",
        "# Train the model\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction\n",
        "pred = search.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and error metrics\n",
        "#test_set_rsquared = nn.score(X_test, y_test)\n",
        "#test_set_rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "\n",
        "# Print R_squared and RMSE value\n",
        "#print(f'R_squared value: , {test_set_rsquared:.2f} %')\n",
        "#print(f'RMSE: , {test_set_rmse:.2f} %')"
      ],
      "metadata": {
        "id": "Af4pvgp0LB1K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}